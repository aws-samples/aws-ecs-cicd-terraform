{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Workshop - Build and Deploy Spring Petclinic Application to Amazon ECS using Terraform and AWS CodePipeline","text":""},{"location":"#introduction","title":"Introduction","text":"<p>This workshop is designed to enable Solutions Architects and engineers to get some hands-on experience using Terraform with AWS Continuous Ingration and Continuous Devlivery tools and services.  The workshop consists of a sequence of steps to build a pipeline for an Amazon ECS workload using the Java PetClinic sample application. The pipeline itself uses AWS CodePipeline, AWS CodeCommit, AWS CodeBuild, Amazon ECS/Fargate and Amazon ECR.</p>"},{"location":"#background","title":"Background","text":"<p>The Spring PetClinic sample application is designed to show how the Spring application framework can be used to build simple, but powerful database-oriented applications. It uses AWS RDS (MySQL) at the backend and it will demonstrate the use of Spring's core functionality. The Spring Framework is a collection of small, well-focused, loosely coupled Java frameworks that can be used independently or collectively to build industrial strength applications of many different types.</p>"},{"location":"#contributors","title":"Contributors","text":"<ul> <li>Irshad A Buchh, Amazon Web Services</li> <li>Mike Rizzo, Amazon Web Services</li> </ul>"},{"location":"architecture/","title":"Architecture","text":"<p>Time Estimate: 15 - 20 minutes  </p> <p></p> What is AWS Fargate? <p>AWS Fargate is a serverless compute engine for containers that works with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS). Fargate makes it easy for you to focus on building your applications. Fargate removes the need to provision and manage servers, lets you specify and pay for resources per application, and improves security through application isolation by design.</p> <p>With Fargate, you can focus on building and operating your applications whether you are running it with ECS or EKS. You only interact with and pay for your containers, and you avoid the operational overhead of scaling, patching, securing, and managing servers. Fargate ensures that the infrastructure your containers run on is always up-to-date with the required patches. </p> <p>With Fargate, you get out-of-box observability through built-in integrations with other AWS services including Amazon CloudWatch Container Insights. Fargate allows you to gather metrics and logs for monitoring your applications through an extensive selection of third party tools with open interfaces.</p> What is Terraform? <p>Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions. </p> <p>Configuration files describe to Terraform the components needed to run a single application or your entire datacenter. Terraform generates an execution plan describing what it will do to reach the desired state, and then executes it to build the described infrastructure. As the configuration changes, Terraform is able to determine what changed and create incremental execution plans which can be applied.</p> <p>The infrastructure Terraform can manage includes low-level components such as compute instances, storage, and networking, as well as high-level components such as DNS entries, SaaS features, etc.</p>"},{"location":"cleanup/","title":"Tearing down the stack","text":"<p>When finished, you can free up resources as follows:</p> <pre><code>cd ../terraform\nterraform destroy\n</code></pre> <p>When prompted enter <code>yes</code> to allow the stack termination to proceed.</p> <p>Once complete, note that you will have to manually empty and delete the S3 bucket used by the pipeline.</p>"},{"location":"contribute/","title":"Contributing Guidelines","text":"<p>Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional  documentation, we greatly value feedback and contributions from our community.</p> <p>Please read through this document before submitting any issues or pull requests to ensure we have all the necessary  information to effectively respond to your bug report or contribution.</p>"},{"location":"contribute/#reporting-bugsfeature-requests","title":"Reporting Bugs/Feature Requests","text":"<p>We welcome you to use the GitHub issue tracker to report bugs or suggest features.</p> <p>When filing an issue, please check existing open, or recently closed, issues to make sure somebody else hasn't already  reported the issue. Please try to include as much information as you can. Details like these are incredibly useful:</p> <ul> <li>A reproducible test case or series of steps</li> <li>The version of our code being used</li> <li>Any modifications you've made relevant to the bug</li> <li>Anything unusual about your environment or deployment</li> </ul>"},{"location":"contribute/#contributing-via-pull-requests","title":"Contributing via Pull Requests","text":"<p>Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that:</p> <ol> <li>You are working against the latest source on the master branch.</li> <li>You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already.</li> <li>You open an issue to discuss any significant work - we would hate for your time to be wasted.</li> </ol> <p>To send us a pull request, please:</p> <ol> <li>Fork the repository.</li> <li>Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change.</li> <li>Ensure local tests pass.</li> <li>Commit to your fork using clear commit messages.</li> <li>Send us a pull request, answering any default questions in the pull request interface.</li> <li>Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation.</li> </ol> <p>GitHub provides additional document on forking a repository and  creating a pull request.</p>"},{"location":"contribute/#finding-contributions-to-work-on","title":"Finding contributions to work on","text":"<p>Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start. </p>"},{"location":"contribute/#code-of-conduct","title":"Code of Conduct","text":"<p>This project has adopted the Amazon Open Source Code of Conduct.  For more information see the Code of Conduct FAQ or contact  opensource-codeofconduct@amazon.com with any additional questions or comments.</p>"},{"location":"contribute/#security-issue-notifications","title":"Security issue notifications","text":"<p>If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page. Please do not create a public github issue.</p>"},{"location":"contribute/#licensing","title":"Licensing","text":"<p>See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution.</p> <p>We may ask you to sign a Contributor License Agreement (CLA) for larger changes.</p>"},{"location":"deploy/","title":"Deploy petclinic application using the pipeline","text":"<p>Time Estimate: 15 - 20 minutes  </p> What is AWS CodePipeline? <p>AWS CodePipeline is a fully managed continuous delivery service that helps you automate your release pipelines for fast and reliable application and infrastructure updates. CodePipeline automates the build, test, and deploy phases of your release process every time there is a code change, based on the release model you define. This enables you to rapidly and reliably deliver features and updates. You can easily integrate AWS CodePipeline with third-party services such as GitHub or with your own custom plugin. With AWS CodePipeline, you only pay for what you use. There are no upfront fees or long-term commitments.</p> <p>You will now use git to push the petclinic application through the pipeline.</p>"},{"location":"deploy/#set-up-a-local-git-repo-for-the-petclinic-application","title":"Set up a local git repo for the petclinic application","text":"<p>Start by switching to the <code>petclinic</code> directory:</p> <pre><code>cd ../petclinic\n</code></pre> <p>Set up your git username and email address:</p> <pre><code>git config --global user.name \"Your Name\"\ngit config --global user.email you@example.com\n</code></pre> <p>Now ceate a local git repo for petclinic as follows:</p> <pre><code>git init\ngit add .\ngit commit -m \"Baseline commit\"\n</code></pre>"},{"location":"deploy/#set-up-the-remote-codecommit-repo","title":"Set up the remote CodeCommit repo","text":"<p>An AWS CodeCommit repo was built as part of the pipeline you created. You will now set this up as a remote repo for your local petclinic repo.</p> <p>For authentication purposes, you can use the AWS IAM git credential helper to generate git credentials based on your IAM role permissions. Run:</p> <pre><code>git config --global credential.helper '!aws codecommit credential-helper $@'\ngit config --global credential.UseHttpPath true\n</code></pre> <p>From the output of the Terraform build, note the Terraform output <code>source_repo_clone_url_http</code>.</p> <pre><code>cd ../terraform\nexport tf_source_repo_clone_url_http=$(terraform output source_repo_clone_url_http)\n</code></pre> <p>Set this up as a remote for your git repo as follows:</p> <pre><code>cd ../petclinic\ngit remote add origin $tf_source_repo_clone_url_http\ngit remote -v\n</code></pre> <p>You should see something like:</p> <pre><code>origin  https://git-codecommit.eu-west-2.amazonaws.com/v1/repos/petclinic (fetch)\norigin  https://git-codecommit.eu-west-2.amazonaws.com/v1/repos/petclinic (push)\n</code></pre>"},{"location":"infrastructure/","title":"Build the infrastructure and pipeline","text":"<p>Time Estimate: 10 - 15 minutes</p> <p>We shall use Terraform to build the above architecture including the AWS CodePipeline.</p>"},{"location":"infrastructure/#set-up-ssm-parameter-for-db-passwd","title":"Set up SSM parameter for DB passwd","text":"<pre><code>aws ssm put-parameter --name /database/password  --value mysqlpassword --type SecureString\n</code></pre>"},{"location":"infrastructure/#edit-terraform-variables","title":"Edit terraform variables","text":"<pre><code>cd terraform\n</code></pre> <p>Edit <code>terraform.tfvars</code>, leave the <code>aws_profile</code> as <code>\"default\"</code>, and set <code>aws_region</code> to the correct value for your environment.</p>"},{"location":"infrastructure/#build","title":"Build","text":"<p>Initialise Terraform:</p> <pre><code>terraform init\n</code></pre> <p>Build the infrastructure and pipeline using terraform:</p> <pre><code>terraform apply\n</code></pre> <p>Terraform will display an action plan. When asked whether you want to proceed with the actions, enter <code>yes</code>.</p> <p>Wait for Terraform to complete the build before proceeding. It will take few minutes to complete \u201cterraform apply\u201d </p>"},{"location":"infrastructure/#explore-the-stack-you-have-built","title":"Explore the stack you have built","text":"<p>Once the build is complete, you can explore your environment using the AWS console: - View the RDS database using the Amazon RDS console.</p> <ul> <li> <p>View the ALB using the Amazon EC2 console.</p> </li> <li> <p>View the ECS cluster using the Amazon ECS console.</p> </li> <li> <p>View the ECR repo using the Amazon ECR console.</p> </li> <li> <p>View the CodeCommit repo using the AWS CodeCommit console.</p> </li> <li> <p>View the CodeBuild project using the AWS CodeBuild console.</p> </li> <li> <p>View the pipeline using the AWS CodePipeline console.</p> </li> </ul> <p>Note that your pipeline starts in a failed state. That is because there is no code to build in the CodeCommit repo! In the next step you will push the petclinic app into the repo to trigger the pipeline.</p>"},{"location":"license/","title":"License","text":"<p>MIT License</p> <p>Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"pipeline/","title":"Trigger the pipeline","text":"<p>Time Estimate: 15 - 20 minutes  </p> <p>To trigger the pipeline, push the master branch to the remote as follows:</p> <pre><code>git push -u origin master\n</code></pre> <p>The pipeline will pull the code, build the docker image, push it to ECR, and deploy it to your ECS cluster. This will take a few minutes. You can monitor the pipeline in the AWS CodePipeline console.</p>"},{"location":"pipeline/#test-the-application","title":"Test the application","text":"<p>From the output of the Terraform build, note the Terraform output <code>alb_address</code>.</p> <pre><code>cd ../terraform\nexport tf_alb_address=$(terraform output alb_address)\necho $tf_alb_address\n</code></pre> <p>Use this in your browser to access the application.</p>"},{"location":"pipeline/#push-a-change-through-the-pipeline-and-re-test","title":"Push a change through the pipeline and re-test","text":"<p>The pipeline can now be used to deploy any changes to the application.</p> <p>You can try this out by changing the welcome message as follows:</p> <pre><code>cd ../petclinic\nvi src/main/resources/messages/messages.properties\n</code></pre> <p>Change the value for the welcome string, for example, to \"Hello\".</p> <p>Commit the change:</p> <pre><code>git add .\ngit commit -m \"Changed welcome string\"\n</code></pre> <p>Push the change to trigger pipeline:</p> <pre><code>git push origin master\n</code></pre> <p>As before, you can use the console to observe the progression of the change through the pipeline. Once done, verify that the application is working with the modified welcome message.</p>"},{"location":"prerequisites/","title":"Prerequisites","text":"<p>Before you build the whole infrastructure, including your CI/CD pipeline, you will need to meet the following pre-requisites.</p>"},{"location":"prerequisites/#aws-account","title":"AWS account","text":"<p>Ensure you have access to an AWS account, and a set of credentials with Administrator permissions. Note: In a production environment we would recommend locking permissions down to the bare minimum needed to operate the pipeline.</p>"},{"location":"prerequisites/#create-an-aws-cloud9-environment","title":"Create an AWS Cloud9 environment","text":"What is AWS Cloud9? <p>AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, PHP, and more, so you don\u2019t need to install files or configure your development machine to start new projects. Since your Cloud9 IDE is cloud-based, you can work on your projects from your office, home, or anywhere using an internet-connected machine. Cloud9 also provides a seamless experience for developing serverless applications enabling you to easily define resources, debug, and switch between local and remote execution of serverless applications. With Cloud9, you can quickly share your development environment with your team, enabling you to pair program and track each other's inputs in real time.</p> <p>Log into the AWS Management Console and search for Cloud9 services in the search bar. Click Cloud9 and create an AWS Cloud9 environment in the us-east-1 region based on Amazon Linux 2.</p>"},{"location":"prerequisites/#configure-the-aws-cloud9-environment","title":"Configure the AWS Cloud9 environment","text":"<p>Launch the AWS Cloud9 IDE. Close the Welcome tab and open a new Terminal tab.</p> <p></p>"},{"location":"prerequisites/#create-and-attach-an-iam-role-for-your-cloud9-instance","title":"Create and attach an IAM role for your Cloud9 instance","text":"<p>By default, Cloud9 manages temporary IAM credentials for you.  Unfortunately these are incomaptible with Terraform. To get around this you need to disable Cloud9 temporary credentials, and create and attach an IAM role for your Cloud9 instance.</p> <ol> <li>Follow this deep link to create an IAM role with Administrator access.</li> <li>Confirm that AWS service and EC2 are selected, then click Next to view permissions.</li> <li>Confirm that AdministratorAccess is checked, then click Next: Tags to assign tags.</li> <li>Take the defaults, and click Next: Review to review.</li> <li>Enter workshop-admin for the Name, and click Create role. </li> <li>Follow this deep link to find your Cloud9 EC2 instance</li> <li>Select the instance, then choose Actions / Instance Settings / Modify IAM Role. Note: If you cannot find this menu option, then look under Actions / Security / Modify IAM Role instead. </li> <li>Choose workshop-admin from the IAM Role drop down, and select Apply </li> <li>Return to your workspace and click the gear icon (in top right corner), or click to open a new tab and choose \"Open Preferences\"</li> <li>Select AWS SETTINGS</li> <li>Turn off AWS managed temporary credentials</li> <li>Close the Preferences tab </li> <li>In the Cloud9 terminal pane, execute the command:     <code>bash     rm -vf ${HOME}/.aws/credentials</code></li> <li>As a final check, use the GetCallerIdentity CLI command to validate that the Cloud9 IDE is using the correct IAM role.     <code>bash     aws sts get-caller-identity --query Arn | grep workshop-admin -q &amp;&amp; echo \"IAM role valid\" || echo \"IAM role NOT valid\"</code></li> </ol>"},{"location":"prerequisites/#upgrade-awscli","title":"Upgrade awscli","text":"<p>Ensure you are running the latest version of AWS CLI:</p> <pre><code>aws --version\npip install awscli --upgrade --user\n</code></pre> <p>Run <code>aws configure</code> to configure your region. Leave all the other fields blank. You should have something like:</p> <pre><code>admin:~/environment $ aws configure\nAWS Access Key ID [None]: \nAWS Secret Access Key [None]: \nDefault region name [None]: us-east-1\nDefault output format [None]: \n</code></pre>"},{"location":"prerequisites/#install-terraform","title":"Install Terraform","text":"<p>Download and install Terraform:</p> <pre><code>wget https://releases.hashicorp.com/terraform/0.13.4/terraform_0.13.4_linux_amd64.zip\nunzip terraform_0.13.4_linux_amd64.zip\nsudo mv terraform /usr/local/bin/\nexport PATH=$PATH:/usr/local/bin/terraform\n</code></pre> <p>Verify that you can run Terraform:</p> <pre><code>terraform version\n</code></pre>"},{"location":"prerequisites/#install-workshop-files","title":"Install workshop files","text":"<p>You will need to import the workshop files into your Cloud9 environment:</p> <pre><code>wget https://github.com/aws-samples/aws-ecs-cicd-terraform/archive/master.zip\nunzip master.zip\ncd aws-ecs-cicd-terraform-master\n</code></pre>"}]}